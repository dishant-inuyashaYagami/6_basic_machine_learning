{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f97fd75",
   "metadata": {},
   "source": [
    "## Reading and Writing .CSV or .TSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d92822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading\n",
    "path_au = \"s3://ibt-global-phrasedoc/qag/v1/filtered/marketplace_id=111172/date=20220301/\"\n",
    "df_au = spark.read.option('delimiter', '\\t').csv(path_au).selectExpr(\"_c0 as asin\", \"_c1 as marketplace_id\" , \"_c2 as query\", \"_c3 as phrase_doc_score\")\n",
    "\n",
    "#Writing\n",
    "path_ibt = \"s3://span-dev-users/dgoyl/Try_EMR/using_emb/conflated_output_17M_qba_hybrid_distribution_\"\\\n",
    "                    + t_string + \"/block_size_\" + str(max_block_size) + \"_IBT_Entries_Number_Of_Chunks_25\"\n",
    "df_au_filtered_sentinel.repartition(25).write.csv(path_ibt, mode = \"overwrite\", sep = '\\t', header=True) # Wrtie Tab Separated File                                                                        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf48c49",
   "metadata": {},
   "source": [
    "## Reading and Writing .Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ee335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading\n",
    "path_pseudo_pairs = \"s3://span-dev-users/dgoyl/Try_EMR/using_emb/conflated_output_17M_qba_hybrid_distribution_\" + t_string + \"/block_size_\" + str(max_block_size) + \"_matchedRecords_pseudo\"\n",
    "df_pairs = spark.read.parquet(path_pseudo_pairs)\n",
    "\n",
    "\n",
    "\n",
    "#Writing\n",
    "path_ibt = \"s3://span-dev-users/dgoyl/Try_EMR/using_emb/conflated_output_17M_qba_hybrid_distribution_\"\\\n",
    "                    + t_string + \"/block_size_\" + str(max_block_size) + \"_IBT_Entries_Number_Of_Chunks_25\"\n",
    "df_au_filtered_sentinel.repartition(25).write.parquet(path_ibt_parquet, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efad5b7",
   "metadata": {},
   "source": [
    "## GroupBy and Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203699c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df_au_list = df_au_filtered.groupby(\"query\").agg(F.collect_set(\"asin\"))\\\n",
    "                           .withColumnRenamed('collect_set(asin)', \"asin_list\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e1c57",
   "metadata": {},
   "source": [
    "## GroupBy and Count and Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1dd6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_group = df.groupBy('keyword').count().sort(col(\"count\").desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bdbe6e",
   "metadata": {},
   "source": [
    "## Merge Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0787e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as f\n",
    "total_list = [f.col(\"keywords\")] + [f.col(\"parent_index\")] + [f.col(\"parent_score\")] + [f.col(\"parent_level\")]\n",
    "df_qba_list = df_qba_refined_parent.withColumn(\"List_Total\", f.array(total_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d330cdbc",
   "metadata": {},
   "source": [
    "## Split Column Into Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e70d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_nodes = df_all_nodes.select(df_all_nodes.Nodes[0].alias('keywords'), \\\n",
    "                                         df_all_nodes.Nodes[1].alias('Threshold_Browse_Index'),\\\n",
    "                                         df_all_nodes.Nodes[2].alias('Threshold_Browse_Score'),\\\n",
    "                                         df_all_nodes.Nodes[3].alias('Threshold_Browse_Level'),\\\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fb961",
   "metadata": {},
   "source": [
    "## Exploding Lists Into Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ba3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df_ibt_explode = df_ibt_list.withColumn('keywords',explode('list_of_keywords'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80bddc",
   "metadata": {},
   "source": [
    "## Using UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,udf\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "def extract_nodes(input_array):\n",
    "    temp_listi = input_array[1:41]    # i denotes index\n",
    "    temp_lists = input_array[41:81]   # s denotes score\n",
    "    temp_listl = input_array[81:121]  # l denotes level\n",
    "    parent_index = input_array[121] #browse node in which query is currently in\n",
    "    parent_score = input_array[122] #browse node in which query is currently in\n",
    "    parent_level = input_array[123] #browse node in which query is currently in\n",
    "\n",
    "    level_node_info = []\n",
    "    index = 0\n",
    "    count = 0\n",
    "    for level in temp_listl:\n",
    "        if level == str(browse_node_level) and float(temp_lists[index]) >= threshold[browse_node_level-1]:\n",
    "            node_info = [input_array[0], temp_listi[index], temp_lists[index], level]\n",
    "            count +=1\n",
    "            level_node_info.append(node_info)\n",
    "        index +=1\n",
    "\n",
    "    if count == 0:\n",
    "        node_info = [input_array[0], parent_index, parent_score, parent_level]\n",
    "        level_node_info.append(node_info)\n",
    "\n",
    "    return level_node_info\n",
    "\n",
    "leaf_udf = udf(lambda z:extract_nodes(z),T.ArrayType(T.ArrayType(T.StringType())))   \n",
    "df_qba_list_2 = df_qba_list.withColumn('Keyword_Level_Nodes',leaf_udf(col(\"List_Total\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
