{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aef286c-34c6-4d18-8490-2b5f4f05d929",
   "metadata": {},
   "source": [
    "## ============   Decision Trees    ==============="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2dc53f-b2f4-4a53-977c-e43ea5c53204",
   "metadata": {},
   "source": [
    "##### Notes: https://www.cse.iitd.ac.in/~parags/teaching/2023/col774/supp_material/dtrees.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf06a1e-352d-4c91-b3d9-caef196a1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_limit          = 8    # grow the tree only upto this depth\n",
    "use_one_hot_encoding = 0    # i do not understand, why one hot encoding can be useful here\n",
    "                            # it makes more sense with neural network; you are right\n",
    "                            # using one hot is incresing the dimension unneccarily and I cannot grow tree completely or use post pruning\n",
    "                            # we remove the original categorical attribute after applying it on the attribute\n",
    "use_post_pruning     = 1    # = 1 avoids overfitting\n",
    "\n",
    "# default with depth: 5           = 0.675\n",
    "# + use_post_pruning              = 0.675\n",
    "# + use_one_hot_encoding          ~ 0.5\n",
    "\n",
    "# default with depth: 8           = 0.65\n",
    "# + use_post_pruning              = 0.677   (0.68 for valid)      ========  BEST\n",
    "# + use_one_hot_encoding          ~ 0.5\n",
    "\n",
    "# need_label_encoding = ['team','opp', 'day_match']\n",
    "# depth = 50   (without use_post_pruning)\n",
    "# + use_one_hot_encoding          = 0.62   (0.99 on train)\n",
    "\n",
    "assert(depth_limit          >= 0)\n",
    "assert(use_one_hot_encoding == 0   or    use_one_hot_encoding == 1)\n",
    "assert(use_post_pruning     == 0   or    use_post_pruning     == 1)  \n",
    "\n",
    "#need_label_encoding = ['team','host','opp','month', 'day_match']\n",
    "#need_label_encoding = ['team','host','opp', 'day_match']\n",
    "need_label_encoding = ['team','opp', 'day_match']\n",
    "#need_label_encoding = ['team', 'day_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c90ca-efc7-464d-8c9b-aa5ab7882925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28eebe3e-5009-4379-b1d9-28cda932a3f0",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04766ac6-8690-4562-b6fb-69fed87e840c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>opp</th>\n",
       "      <th>host</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>toss</th>\n",
       "      <th>day_match</th>\n",
       "      <th>bat_first</th>\n",
       "      <th>format</th>\n",
       "      <th>fow</th>\n",
       "      <th>score</th>\n",
       "      <th>rpo</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>australia</td>\n",
       "      <td>south_africa</td>\n",
       "      <td>sri_lanka</td>\n",
       "      <td>2012</td>\n",
       "      <td>sep</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>146</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>india</td>\n",
       "      <td>australia</td>\n",
       "      <td>india</td>\n",
       "      <td>2020</td>\n",
       "      <td>jan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>340</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>canada</td>\n",
       "      <td>scotland</td>\n",
       "      <td>scotland</td>\n",
       "      <td>2009</td>\n",
       "      <td>jul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>286</td>\n",
       "      <td>5.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>australia</td>\n",
       "      <td>england</td>\n",
       "      <td>australia</td>\n",
       "      <td>1987</td>\n",
       "      <td>jan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new_zealand</td>\n",
       "      <td>pakistan</td>\n",
       "      <td>uae</td>\n",
       "      <td>2009</td>\n",
       "      <td>nov</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>153</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          team           opp       host  year month  toss  day_match  \\\n",
       "0    australia  south_africa  sri_lanka  2012   sep     1          0   \n",
       "1        india     australia      india  2020   jan     0          0   \n",
       "2       canada      scotland   scotland  2009   jul     1          1   \n",
       "3    australia       england  australia  1987   jan     1          1   \n",
       "4  new_zealand      pakistan        uae  2009   nov     0          0   \n",
       "\n",
       "   bat_first  format  fow  score   rpo  result  \n",
       "0          0       1    5    146  7.30       1  \n",
       "1          1       0    6    340  6.80       1  \n",
       "2          0       0    4    286  5.72       1  \n",
       "3          1       0    6    225  4.50       1  \n",
       "4          0       1    5    153  7.65       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dataset_cricket_match/train.csv')\n",
    "df = df.drop(\"Unnamed: 0\", axis = 1)\n",
    "df.head(5)\n",
    "# fow: fall of wicket;   rpo: run per over or run rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd0dff-aacb-4d60-96a5-b2ac7cff4dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "576ea42b-bbb2-496f-86ce-2fcdae5f8a7f",
   "metadata": {},
   "source": [
    "### Convert Categorical Data to One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5232448c-c72c-4470-93ee-6d79b0e4fc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>opp</th>\n",
       "      <th>host</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>toss</th>\n",
       "      <th>day_match</th>\n",
       "      <th>bat_first</th>\n",
       "      <th>format</th>\n",
       "      <th>fow</th>\n",
       "      <th>score</th>\n",
       "      <th>rpo</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>australia</td>\n",
       "      <td>south_africa</td>\n",
       "      <td>sri_lanka</td>\n",
       "      <td>2012</td>\n",
       "      <td>sep</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>146</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>india</td>\n",
       "      <td>australia</td>\n",
       "      <td>india</td>\n",
       "      <td>2020</td>\n",
       "      <td>jan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>340</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>canada</td>\n",
       "      <td>scotland</td>\n",
       "      <td>scotland</td>\n",
       "      <td>2009</td>\n",
       "      <td>jul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>286</td>\n",
       "      <td>5.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>australia</td>\n",
       "      <td>england</td>\n",
       "      <td>australia</td>\n",
       "      <td>1987</td>\n",
       "      <td>jan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new_zealand</td>\n",
       "      <td>pakistan</td>\n",
       "      <td>uae</td>\n",
       "      <td>2009</td>\n",
       "      <td>nov</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>153</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          team           opp       host  year month  toss  day_match  \\\n",
       "0    australia  south_africa  sri_lanka  2012   sep     1          0   \n",
       "1        india     australia      india  2020   jan     0          0   \n",
       "2       canada      scotland   scotland  2009   jul     1          1   \n",
       "3    australia       england  australia  1987   jan     1          1   \n",
       "4  new_zealand      pakistan        uae  2009   nov     0          0   \n",
       "\n",
       "   bat_first  format  fow  score   rpo  result  \n",
       "0          0       1    5    146  7.30       1  \n",
       "1          1       0    6    340  6.80       1  \n",
       "2          0       0    4    286  5.72       1  \n",
       "3          1       0    6    225  4.50       1  \n",
       "4          0       1    5    153  7.65       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_df_to_one_hot(df):\n",
    "    for attr_name in need_label_encoding:\n",
    "        unique_attr = df[attr_name].unique()\n",
    "        for attr_val in unique_attr:\n",
    "            new_attr_name = attr_name + \"_\" + str(attr_val)\n",
    "            df[new_attr_name] = 0\n",
    "            df.loc[df[attr_name] == attr_val, new_attr_name] = 1\n",
    "        df = df.drop(attr_name, axis = 1) # drops columns\n",
    "    return df\n",
    "    \n",
    "if use_one_hot_encoding == 1:\n",
    "   df = convert_df_to_one_hot(df) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67023b20-b573-4e50-b2e4-ef5b315ac88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cced04dd-fdf6-43ff-90ad-b0138b6b4363",
   "metadata": {},
   "source": [
    "### STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb3e181-a851-4725-872c-ac989d0863a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows         :  7827\n",
      "number of features     :  12\n",
      "number of class labels :  2\n"
     ]
    }
   ],
   "source": [
    "print (\"number of rows         : \", df.shape[0])\n",
    "print (\"number of features     : \", df.shape[1]-1)  # excluding the class labels\n",
    "print (\"number of class labels : \", 2)\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0416724-25f0-4edf-b402-1a9050cb6e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7531863c-fd12-470b-b76f-8b6f105c9c21",
   "metadata": {},
   "source": [
    "### Identify Attributes as Categorical or Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757d84a1-5b65-4df7-99e8-7ee32cc151e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_list = df.axes[1].tolist()\n",
    "attr_list.remove('result')\n",
    "#print (attr_list)\n",
    "cont_attr = ['fow', 'score', 'rpo']\n",
    "#print (cont_attr)\n",
    "\n",
    "# only fow, score, rpo are continuous = 0; rest are categorical = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf3942-82ba-408f-a961-dc65e37106c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bee02b3a-fa1f-4cfd-9644-412414b89821",
   "metadata": {},
   "source": [
    "### Compute Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "295b161c-aaa9-49e1-b2d8-7a7283e3c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999669243084066\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def getEntropyDataframe(df):\n",
    "    cnt_dict =  df[\"result\"].value_counts().to_dict()\n",
    "    cnt_list =  [int(cnt_dict[0]), int(cnt_dict[1])]\n",
    "    return getEntropyList(cnt_list)\n",
    "\n",
    "def getEntropyList(cnt_list):\n",
    "    if cnt_list[0] == 0 or cnt_list[1] == 0:     # 0 error when 0 entropy; all data items have the same class label \n",
    "        return 0\n",
    "    total    =  sum(cnt_list)\n",
    "    p0       =  cnt_list[0]/total\n",
    "    p1       =  cnt_list[1]/total\n",
    "    entropy  =  -1*(p0*math.log(p0,2) + p1*math.log(p1,2))\n",
    "    return entropy\n",
    "\n",
    "print (getEntropyDataframe(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98b1dcf2-8b8e-411b-a4c1-2589078dbda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999665065933905\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def getEntropyPostCatAttributeSplit(df, attribute):\n",
    "    assert (attribute not in cont_attr)\n",
    "    entropy         = 0\n",
    "    dict_attr_count = df.value_counts([attribute,'result']).to_dict()\n",
    "    total           = sum(dict_attr_count.values())\n",
    "    unique_attr     = df[attribute].unique()\n",
    "    for attr in unique_attr:\n",
    "        if (attr,1) not in dict_attr_count:\n",
    "            dict_attr_count[(attr,1)] = 0\n",
    "        if (attr,0) not in dict_attr_count:\n",
    "            dict_attr_count[(attr,0)] = 0\n",
    "        attr_cnt_list  = [dict_attr_count[(attr,0)], dict_attr_count[(attr,1)]] \n",
    "        prob           =  sum(attr_cnt_list)/total\n",
    "        entropy       += getEntropyList(attr_cnt_list)*prob\n",
    "    return entropy\n",
    "\n",
    "def getEntropyPostContAttributeSplit(df, attribute):\n",
    "    assert (attribute in cont_attr)\n",
    "    entropy         = 0\n",
    "    mean_attr       = df.loc[:, attribute].mean()\n",
    "    low_val_dict    = df[df[attribute] <=   mean_attr].value_counts('result').to_dict()\n",
    "    high_val_dict   = df[df[attribute]  >   mean_attr].value_counts('result').to_dict()\n",
    "    total           = df.shape[0]\n",
    "    \n",
    "    dict_attr_count = {}\n",
    "    if 1 not in low_val_dict:\n",
    "        low_val_dict[1] = 0\n",
    "    if 0 not in low_val_dict:\n",
    "        low_val_dict[0] = 0\n",
    "    attr_cnt_list  = [low_val_dict[0], low_val_dict[1]] \n",
    "    prob           =  sum(attr_cnt_list)/total\n",
    "    low_val_etpy   = getEntropyList(attr_cnt_list)*prob\n",
    "\n",
    "    dict_attr_count = {}\n",
    "    if 1 not in high_val_dict:\n",
    "        high_val_dict[1] = 0\n",
    "    if 0 not in high_val_dict:\n",
    "        high_val_dict[0] = 0\n",
    "    attr_cnt_list  = [high_val_dict[0], high_val_dict[1]] \n",
    "    prob           =  sum(attr_cnt_list)/total\n",
    "    high_val_etpy  = getEntropyList(attr_cnt_list)*prob\n",
    "    \n",
    "    return low_val_etpy + high_val_etpy\n",
    "\n",
    "#print (getEntropyPostCatAttributeSplit(df, 'team'))\n",
    "print (getEntropyPostContAttributeSplit(df, 'fow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868a849-a085-41f3-8f27-1022be9dcfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1f9d90b-b6f7-478e-ac8f-c32572bd8e3f",
   "metadata": {},
   "source": [
    "### Choose Best Attribute & Split Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db2d8361-0844-4a64-a932-1ca2153b1a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['team', 'opp', 'host', 'year', 'month', 'toss', 'day_match', 'bat_first', 'format', 'fow', 'score', 'rpo']\n"
     ]
    }
   ],
   "source": [
    "def chooseBestAttr(df, attr_list):   # attr_list: list of attributes to choose from\n",
    "    assert (len(attr_list) > 0)\n",
    "    min_entropy = 1\n",
    "    best_attr   = \"\"\n",
    "    for attr_name in attr_list:       # choose the best attribute based on minimum entropy\n",
    "        if attr_name not in cont_attr:\n",
    "            entropy = getEntropyPostCatAttributeSplit(df, attr_name)      # categorical attribute\n",
    "        else:\n",
    "            entropy = getEntropyPostContAttributeSplit(df, attr_name)     # continuous attribute\n",
    "            \n",
    "        #print (\"entropy of \", attr_name, \" is \", entropy)\n",
    "        if entropy <= min_entropy:\n",
    "            best_attr = attr_name\n",
    "    return best_attr\n",
    "\n",
    "def splitMinEntropy(df, attr_list, child_df_list, selected_attr, attribute_value_list, mean_attr_val):\n",
    "    selected_attr[0]   = chooseBestAttr(df, attr_list)\n",
    "    #print (\"best attribute to split on: \", selected_attr[0])\n",
    "    attr_name = selected_attr[0]\n",
    "    \n",
    "    if attr_name not in cont_attr:\n",
    "        unique_attr = df[attr_name].unique()\n",
    "        for attr_val in unique_attr:\n",
    "            childDf = df.loc[df[attr_name] == attr_val]\n",
    "            child_df_list.append(childDf)\n",
    "            attribute_value_list.append(attr_val)\n",
    "    else:\n",
    "        mean_attr     = df.loc[:, attr_name].mean()\n",
    "        low_val_df    = df[df[attr_name] <=   mean_attr]\n",
    "        high_val_df   = df[df[attr_name]  >   mean_attr]\n",
    "        child_df_list.append(low_val_df)\n",
    "        child_df_list.append(high_val_df)\n",
    "        mean_attr_val[0] = mean_attr\n",
    "    #attr_list.remove(best_attr)             # no need to split on this attribute again since already utilized \n",
    "\n",
    "attr_list = df.axes[1].tolist()\n",
    "attr_list.remove('result')\n",
    "print (attr_list)\n",
    "child_df_list        = []\n",
    "attribute_value_list = []\n",
    "selected_attr        = [0]\n",
    "mean_attr_val        = [0]\n",
    "splitMinEntropy(df, attr_list, child_df_list, selected_attr, attribute_value_list, mean_attr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dbc813-3f86-4505-908d-0883fa844bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87904f27-099e-40b8-8f27-5f440f949408",
   "metadata": {},
   "source": [
    "### Tree Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eec5137-60a0-4d38-8161-3cc959f0cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_nodes = [0]\n",
    "class treeNode:\n",
    "    attribute_split  = \"\"    # attribute that we choose this node to split into\n",
    "    attribute_value  = \"\"    # value corresponding to it as child node   (categorical type)\n",
    "    mean_value       = -1    # mean corresponding  to it as parenet node (continuous  type)\n",
    "    isLeaf           = 0\n",
    "    childNodeList    = []    # list of all child nodes of type treeNode (corresponding to attribute_value)\n",
    "                             # for continuous type, childNodeList[0] corresponds to <= mean_value and childNodeList[0] for rest\n",
    "    majorityClass    = -1    # takes value 0 or 1 only when encountered\n",
    "    depth            = 0     # root has depth = 0\n",
    "    isPruningLeaf    = 0     # = 1 for internal nodes as well; when doing post pruning\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4bfab-1e30-48c6-865b-913f82794d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecd2ba09-0d24-4ba0-a16f-abeec27ae662",
   "metadata": {},
   "source": [
    "### Create Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11fed03d-961c-4226-99b5-917c35a15369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of nodes in the tree:  1113\n",
      "total number of incorrect decision taken by DT on the training set:  2154\n"
     ]
    }
   ],
   "source": [
    "def splitAndUpdatePara(root, df, attr_list):\n",
    "    #print (\"\\nnumber of data points at the node: \", df.shape[0], \" depth: \", root.depth)\n",
    "    lable_cnt_dict = df.value_counts('result').to_dict()   # assign the label based on majorityClass\n",
    "    if 0 not in lable_cnt_dict:\n",
    "        root.majorityClass = 1\n",
    "        root.isLeaf = 1\n",
    "        return\n",
    "    if 1 not in lable_cnt_dict:\n",
    "        root.majorityClass = 0\n",
    "        root.isLeaf = 1\n",
    "        return\n",
    "\n",
    "    if lable_cnt_dict[0] > lable_cnt_dict[1]:\n",
    "        root.majorityClass = 0\n",
    "    else:\n",
    "        root.majorityClass = 1\n",
    "            \n",
    "    if root.depth >= depth_limit  or  len(df.value_counts('result').to_dict()) <= 1  or  len(attr_list) == 0:\n",
    "        #print (\"probabilistic decision taken at leaf node; num wrong pred: \", min(lable_cnt_dict.values()))\n",
    "        total_wrong_decision[0] += min(lable_cnt_dict.values())\n",
    "        root.isLeaf = 1\n",
    "        return\n",
    "        \n",
    "    child_df_list        = []\n",
    "    attribute_value_list = []\n",
    "    mean_attr_val        = [-1]\n",
    "    selected_attr        = [-1]  # contains only one attribute # declaring as list since we are passing it inside method\n",
    "    splitMinEntropy(df, attr_list, child_df_list, selected_attr, attribute_value_list, mean_attr_val)\n",
    "\n",
    "    if selected_attr[0] in cont_attr:                      # attribute type: continuous\n",
    "        root.mean_value      = mean_attr_val[0]\n",
    "        #print (\"mean: \", root.mean_value)\n",
    "    root.attribute_split = selected_attr[0]\n",
    "    new_attr_list = attr_list.copy()\n",
    "    new_attr_list.remove(root.attribute_split)             # no need to split on this attribute again since already utilized\n",
    "\n",
    "    \n",
    "    #print (\"number of children: \", len(child_df_list), \" at depth: \", root.depth)\n",
    "    index = 0\n",
    "    for child_df in child_df_list:\n",
    "        global childNode\n",
    "        childNode = treeNode()\n",
    "        childNode.childNodeList = []\n",
    "        childNode.depth         = root.depth + 1\n",
    "        childNode.isPruningLeaf = 0\n",
    "        total_num_nodes[0]     += 1\n",
    "        (root.childNodeList).append(childNode)\n",
    "        if selected_attr[0] not in cont_attr:              # attribute type: categorical\n",
    "            childNode.attribute_value = attribute_value_list[index]\n",
    "        splitAndUpdatePara(childNode, child_df, new_attr_list)\n",
    "        index += 1\n",
    "\n",
    "def createTree(root):\n",
    "    attr_list = df.axes[1].tolist()\n",
    "    attr_list.remove('result')\n",
    "    #print (attr_list)\n",
    "    splitAndUpdatePara(root, df, attr_list)\n",
    "\n",
    "total_wrong_decision = [0]\n",
    "root = treeNode()\n",
    "root.childNodeList = []\n",
    "root.depth         = 0\n",
    "root.isPruningLeaf = 0\n",
    "total_num_nodes[0] = 1 \n",
    "createTree(root)\n",
    "print (\"total number of nodes in the tree: \", total_num_nodes[0])\n",
    "print (\"total number of incorrect decision taken by DT on the training set: \", total_wrong_decision[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e1ab9d-468d-4030-979b-afc667b4cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78577d-c769-47d7-ab02-13e08ff83090",
   "metadata": {},
   "source": [
    "### Predict on Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bf9fa4c-0f26-4e38-865c-755161d287d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictTree(df, root, lable_0_indexes, lable_1_indexes):\n",
    "    if df.empty:\n",
    "        return\n",
    "\n",
    "    isPruningLeaf = 0\n",
    "    if use_post_pruning == 1 and root.isPruningLeaf == 1:\n",
    "        isPruningLeaf = 1\n",
    "    \n",
    "    if root.isLeaf == 1 or isPruningLeaf == 1:\n",
    "        indexes         =  list(df.index.values)\n",
    "        #print (\"encountered leaf node at depth: \", root.depth, \" and predicted \", len(indexes), \" labels\")\n",
    "        if root.majorityClass == 1:\n",
    "            lable_1_indexes += indexes\n",
    "        else:\n",
    "            lable_0_indexes += indexes\n",
    "        return\n",
    "\n",
    "    attr_name = root.attribute_split\n",
    "    if attr_name in cont_attr:                     # attribute type: continuous\n",
    "        left_df  = df.loc[df[attr_name] <= root.mean_value]\n",
    "        right_df = df.loc[df[attr_name]  > root.mean_value]\n",
    "        if len(root.childNodeList) >= 1:\n",
    "            predictTree(left_df,  root.childNodeList[0], lable_0_indexes, lable_1_indexes)        # there is a boundary case here; please take care later =====\n",
    "        if len(root.childNodeList) >= 2:\n",
    "            predictTree(right_df, root.childNodeList[1], lable_0_indexes, lable_1_indexes)\n",
    "        return\n",
    "\n",
    "    list_attr_value = []\n",
    "    if attr_name not in cont_attr:                 # attribute type: categorical\n",
    "        for childNode in root.childNodeList:\n",
    "            attr_value = childNode.attribute_value\n",
    "            child_df   = df.loc[df[attr_name] == attr_value]\n",
    "            #print (\"child_df : \",  child_df.shape[0])\n",
    "            list_attr_value.append(attr_value)\n",
    "            predictTree(child_df, childNode, lable_0_indexes, lable_1_indexes)\n",
    "\n",
    "    # if a new attribute value, then assign then consider the node as leaf node and assign the majority class label\n",
    "    remaining_df    = df.loc[~df[attr_name].isin(list_attr_value)].copy()\n",
    "    if remaining_df.empty:\n",
    "        return\n",
    "        \n",
    "    indexes         =  list(remaining_df.index.values)\n",
    "    #print (\"encountered new attribute value for attribute: \", attr_name)\n",
    "    if root.majorityClass == 1:\n",
    "        lable_1_indexes += indexes\n",
    "    else:\n",
    "        lable_0_indexes += indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03eaeb-673f-4eda-853d-54d57042e066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ad9d0-08eb-42b8-befe-c6984680ece1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d657da6e-0e1e-4c57-9572-926b6b9581d8",
   "metadata": {},
   "source": [
    "### Loading & Predicting Training, Validation, Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4925ed24-b6f1-4720-8e8d-3a9732fae8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows         :  7827\n",
      "number of rows         :  870\n",
      "number of rows         :  967\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "train_df = pd.read_csv('dataset_cricket_match/train.csv')\n",
    "valid_df = pd.read_csv('dataset_cricket_match/val.csv')\n",
    "test_df  = pd.read_csv('dataset_cricket_match/test.csv')\n",
    "df_list  = [train_df, valid_df, test_df] \n",
    "\n",
    "index = 0\n",
    "for df in df_list:\n",
    "    df = df.drop(\"Unnamed: 0\", axis = 1)\n",
    "    if use_one_hot_encoding == 1:           # converting categorical attributes to one hot encoded vector\n",
    "        df = convert_df_to_one_hot(df) \n",
    "    print (\"number of rows         : \", df.shape[0])\n",
    "    df_list[index] = df\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c92bd0d0-2e39-46b4-bfb4-13e4330b77ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy:  0.7247987734764277\n",
      "\n",
      "accuracy:  0.6344827586206897\n",
      "\n",
      "accuracy:  0.6763185108583247\n"
     ]
    }
   ],
   "source": [
    "def getAccuracy(df, enable_prints):\n",
    "    lable_0_indexes = []\n",
    "    lable_1_indexes = []\n",
    "    predictTree(df, root, lable_0_indexes, lable_1_indexes)\n",
    "    \n",
    "    class_0_df     = pd.DataFrame(index=lable_0_indexes, columns=['predicted_result'])\n",
    "    class_1_df     = pd.DataFrame(index=lable_1_indexes, columns=['predicted_result'])\n",
    "    class_0_df[\"predicted_result\"] = 0\n",
    "    class_1_df[\"predicted_result\"] = 1\n",
    "    if class_0_df.empty:\n",
    "        full_df = class_1_df\n",
    "    elif class_1_df.empty:\n",
    "        full_df = class_0_df\n",
    "    else:\n",
    "        full_df = pd.concat([class_0_df, class_1_df])\n",
    "    pred_df = df.merge(full_df, how = \"left\", left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "    y_true = pred_df['result'].tolist()\n",
    "    y_pred = pred_df['predicted_result'].tolist()\n",
    "    classes = [0,1]\n",
    "    if enable_prints == 1:\n",
    "        print(\"PR Report         : \\n\", classification_report(y_true, y_pred, labels=classes, zero_division=0))\n",
    "        print(\"Confusion Matrix  : \\n\", confusion_matrix(y_true, y_pred))\n",
    "        #print(\"\\nAccuracy        : \", accuracy_score(y_true, y_pred))\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "for df in df_list:\n",
    "    print (\"\\naccuracy: \", getAccuracy(df,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c025cab5-f054-4274-bba6-ea80c619ea6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd674395-d47f-4987-8fe7-009bdad58ca0",
   "metadata": {},
   "source": [
    "### Post-Pruning Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b19f19be-97c3-4ee1-9d67-7d03c804ea02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtained better validation test accuracy:  0.635632183908046\n",
      "obtained better validation test accuracy:  0.6367816091954023\n",
      "obtained better validation test accuracy:  0.6379310344827587\n",
      "obtained better validation test accuracy:  0.6402298850574712\n",
      "obtained better validation test accuracy:  0.6413793103448275\n",
      "obtained better validation test accuracy:  0.6436781609195402\n",
      "obtained better validation test accuracy:  0.6459770114942529\n",
      "obtained better validation test accuracy:  0.6505747126436782\n",
      "obtained better validation test accuracy:  0.6517241379310345\n",
      "obtained better validation test accuracy:  0.6563218390804598\n",
      "obtained better validation test accuracy:  0.6586206896551724\n",
      "obtained better validation test accuracy:  0.6620689655172414\n",
      "obtained better validation test accuracy:  0.6632183908045977\n",
      "obtained better validation test accuracy:  0.6655172413793103\n",
      "obtained better validation test accuracy:  0.6666666666666666\n",
      "obtained better validation test accuracy:  0.6689655172413793\n",
      "obtained better validation test accuracy:  0.6701149425287356\n",
      "obtained better validation test accuracy:  0.6758620689655173\n",
      "obtained better validation test accuracy:  0.6770114942528735\n",
      "obtained better validation test accuracy:  0.6793103448275862\n",
      "obtained better validation test accuracy:  0.6804597701149425\n",
      "obtained better validation test accuracy:  0.6816091954022988\n",
      "obtained better validation test accuracy:  0.6827586206896552\n",
      "\n",
      "train      accuracy:  0.6920914782164304\n",
      "\n",
      "validation accuracy:  0.6827586206896552\n",
      "\n",
      "test       accuracy:  0.6773526370217167\n"
     ]
    }
   ],
   "source": [
    "if use_post_pruning == 1:\n",
    "    df = df_list[1]   # validation data set\n",
    "    \n",
    "    def runDFS(root, current_best_accuracy):  \n",
    "        for childNode in root.childNodeList:\n",
    "            runDFS(childNode, current_best_accuracy)\n",
    "            \n",
    "        root.isPruningLeaf = 1\n",
    "        accuracy = getAccuracy(df,0)\n",
    "        if current_best_accuracy[0] < accuracy:\n",
    "            print (\"obtained better validation test accuracy: \", accuracy)\n",
    "            current_best_accuracy[0] = accuracy\n",
    "        elif current_best_accuracy[0] > accuracy:\n",
    "            root.isPruningLeaf = 0\n",
    "    # note that visited vector is not required for dfs here; since it is a simple k-ary tree\n",
    "    \n",
    "    current_best_accuracy = [0]\n",
    "    current_best_accuracy[0] = getAccuracy(df,0)\n",
    "    runDFS(root, current_best_accuracy)\n",
    "\n",
    "print (\"\\ntrain      accuracy: \", getAccuracy(df_list[0],0))\n",
    "print (\"\\nvalidation accuracy: \", getAccuracy(df_list[1],0))\n",
    "print (\"\\ntest       accuracy: \", getAccuracy(df_list[2],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42709171-243f-49e6-ae59-c81fe29ee5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20409962-9691-4725-a654-53ef570fd872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff741e-2997-45e5-b23b-1ffd67d682af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795ab4f-1595-4791-8fc7-f8d03c487499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acbcc388-03b5-4418-93c9-da0a60483440",
   "metadata": {},
   "source": [
    "##### JUNK (Entropy Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "533a6c24-1360-4a12-ab54-b07102a9cfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy for [8|2]  : 0.7219280948873623\n",
      "entropy for [12|8] : 0.9709505944546686\n",
      "total entropy      : 0.8879430945988998\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "entropy_1     = -1*(1/5*math.log(1/5,2) +  4/5*math.log(4/5,2))         # base 2\n",
    "entropy_2     = -1*(8/20*math.log(8/20,2) +  12/20*math.log(12/20,2))   # base 2\n",
    "entropy_full  =  1/3*entropy_1 + 2/3*entropy_2\n",
    "\n",
    "print (\"entropy for [8|2]  :\",  entropy_1)\n",
    "print (\"entropy for [12|8] :\",  entropy_2)\n",
    "print (\"total entropy      :\",  entropy_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc6929-fabc-4ec4-a654-69c06c2a64f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
